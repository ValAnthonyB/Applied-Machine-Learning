{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f11b274",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from scipy.stats import uniform, randint, loguniform, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59be5f8",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f05900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 8116, 2: 8116, 1: 8116})\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv('C:/Users/vabalagon/Desktop/Meta/New Workflow/data/2 data for modeling (With PCA).csv')\n",
    "\n",
    "# Get the features and target variable from the dataframe\n",
    "X = data.drop(['Survey ID', 'Response Date', 'Likelihood to Recommend'], axis=1).to_numpy()\n",
    "y = data['Likelihood to Recommend'].to_numpy()\n",
    "\n",
    "# Split the data into test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.copy(), y, test_size = 0.25, shuffle=True, random_state=42) #, stratify=y_smote\n",
    "\n",
    "# Apply SMOTE oversampling to the TRAINING SET ONLY\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(y_train_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d17cc06",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c03aef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee0688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=y_train_smote\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecefce64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "215 fits failed out of a total of 1000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03855 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06563 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06958 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.0263 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.07171 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.0297 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09774 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08565 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09625 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03563 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.05393 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.01486 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.07585 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.01521 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.05487 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.04915 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03344 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.04389 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06119 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00535 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00255 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.0568 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06865 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06322 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02464 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09583 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.01525 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.04053 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08529 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09972 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09664 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.05405 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06797 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08626 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03369 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09726 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.07507 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03983 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03212 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08484 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.01485 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.04845 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08537 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.87587795 0.87468702 0.87908139        nan 0.86655563 0.88138148\n",
      " 0.88466722        nan 0.88244944 0.87292069 0.8740295         nan\n",
      " 0.88142283 0.88183329 0.87394798 0.86696599 0.88244949        nan\n",
      " 0.88220288        nan 0.88240836 0.86183225 0.88491363 0.87419355\n",
      "        nan 0.87628844 0.87579585 0.88023155 0.88010814 0.86754113\n",
      "        nan 0.8720174  0.87275669        nan 0.88125792 0.87554962\n",
      " 0.87591852 0.87300297 0.87641179 0.87669935 0.87550834        nan\n",
      " 0.87653477        nan 0.87431726 0.87862986 0.86873219 0.87752044\n",
      " 0.86877238 0.87632949 0.86310609        nan        nan 0.87904039\n",
      " 0.87468684 0.87366004 0.87702783 0.87550842 0.86409108 0.87374174\n",
      " 0.88310666 0.87172926 0.87218145 0.87698749        nan 0.8722638\n",
      " 0.87678176        nan 0.87542652        nan 0.86901868 0.86795182\n",
      " 0.87255159        nan        nan 0.86967638        nan 0.87698683\n",
      "        nan        nan 0.86930682 0.87493355 0.87226307 0.87205865\n",
      " 0.87275642 0.88224418        nan 0.87546729 0.87115485        nan\n",
      " 0.87616536 0.87312595 0.88474943        nan 0.87710983 0.87279747\n",
      " 0.87152453 0.88253134 0.87181194 0.86380363        nan 0.86906047\n",
      "        nan 0.84602014        nan        nan 0.8757548  0.87694563\n",
      " 0.87316738        nan 0.87037455        nan 0.86992307        nan\n",
      "        nan        nan 0.8729213  0.87727442        nan 0.86811599\n",
      " 0.87427651 0.87481038 0.87817787 0.87427611 0.87485123 0.88056046\n",
      " 0.87234646 0.87715116 0.8711138  0.87053822 0.84610171 0.87431693\n",
      " 0.87045698        nan 0.86864973 0.86400913 0.8829834  0.87349591\n",
      " 0.86885471 0.88088824 0.87867083 0.87103195        nan 0.86905989\n",
      "        nan 0.862777          nan 0.88154573 0.87768508 0.87526234\n",
      " 0.87616604 0.87624718 0.88158724 0.87275669 0.8753856  0.88195632\n",
      " 0.87887578 0.88002597 0.87563155 0.87563134 0.87193522        nan\n",
      " 0.87575462 0.87390647 0.8793689  0.87349556 0.88240828 0.88019095\n",
      " 0.87127835 0.87862968        nan 0.87912242 0.87082642        nan\n",
      " 0.84076337 0.87945135 0.87743862 0.86520009 0.8711549         nan\n",
      " 0.87016945 0.87735637 0.87735637 0.88392762 0.88014912 0.87776708\n",
      " 0.87805461 0.84022741 0.87074378 0.86643179 0.87542629 0.86162773\n",
      " 0.87969751 0.87168894 0.87160679 0.8711139         nan        nan\n",
      " 0.8735375  0.86934805]\n",
      "  warnings.warn(\n",
      "C:\\Users\\vabalagon\\.conda\\envs\\DataScienceStandard\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.90608045 0.90308218 0.94888693        nan 0.87695064 0.96372392\n",
      " 0.94605302        nan 0.95200836 0.9049099  0.90780541        nan\n",
      " 0.94576551 0.97398143 0.89328675 0.87725866 0.95057089        nan\n",
      " 0.94681283        nan 0.93922493 0.86812041 0.96663998 0.9206094\n",
      "        nan 0.91456162 0.90525896 0.92784819 0.93430665 0.87792609\n",
      "        nan 0.8957819  0.8895493         nan 0.93474815 0.89819475\n",
      " 0.94676149 0.90091568 0.9011416  0.90122377 0.90167555        nan\n",
      " 0.9250759         nan 0.91251834 0.91888441 0.88158155 0.91703618\n",
      " 0.89366665 0.90614202 0.86787395        nan        nan 0.92720131\n",
      " 0.89996083 0.90394477 0.90744609 0.90205545 0.87356228 0.91769334\n",
      " 0.96162925 0.91602995 0.89542246 0.93543614        nan 0.88930288\n",
      " 0.93309503        nan 0.89902644        nan 0.88408684 0.87701228\n",
      " 0.88641758        nan        nan 0.88331673        nan 0.90435542\n",
      "        nan        nan 0.9001559  0.89940635 0.90203497 0.89299929\n",
      " 0.88877928 0.96282032        nan 0.944595   0.88824523        nan\n",
      " 0.90020723 0.90727152 0.97116803        nan 0.90501258 0.89926256\n",
      " 0.89061714 0.956557   0.90684023 0.87054366        nan 0.89759925\n",
      "        nan 0.84923799        nan        nan 0.90447867 0.92226254\n",
      " 0.90615237        nan 0.88299847        nan 0.88428199        nan\n",
      "        nan        nan 0.89669563 0.90917105        nan 0.87920954\n",
      " 0.89266042 0.8961309  0.92333035 0.89189032 0.90258936 0.95114583\n",
      " 0.89124346 0.9340705  0.89315325 0.90624476 0.84728703 0.91848395\n",
      " 0.89343052        nan 0.87904525 0.87174489 0.96412432 0.88946718\n",
      " 0.88639704 0.92686253 0.90492016 0.88763946        nan 0.89207515\n",
      "        nan 0.86754555        nan 0.93313615 0.92513748 0.90401659\n",
      " 0.94462578 0.90637822 0.97295468 0.90753845 0.90681967 0.94756238\n",
      " 0.94755214 0.93161646 0.91747772 0.89450861 0.89002162        nan\n",
      " 0.9194286  0.89824614 0.90805181 0.90821613 0.94980082 0.95829225\n",
      " 0.88282388 0.9380852         nan 0.93963564 0.88705419        nan\n",
      " 0.83955528 0.94732625 0.90689163 0.87391133 0.8853292         nan\n",
      " 0.88194079 0.91956205 0.92913168 0.96698907 0.93545664 0.91770363\n",
      " 0.91339111 0.84235865 0.91143    0.88157116 0.91687182 0.8642905\n",
      " 0.91954153 0.89053497 0.8906171  0.88793726        nan        nan\n",
      " 0.89555586 0.8820948 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameter: {'colsample_bytree': 0.7955160864261275, 'gamma': 0.2393314544058757, 'max_depth': 6, 'n_estimators': 144, 'subsample': 0.8555511385430487}\n",
      "Training set cross-validation balanced accuracy score: 0.88491362869749\n",
      "Test set balanced accuracy score: 0.7616455441270329\n"
     ]
    }
   ],
   "source": [
    "# xgb_model_clf = xgb.XGBClassifier(objective=\"multi:softmax\",\n",
    "#                                   eval_metric='mlogloss',\n",
    "#                                   use_label_encoder=False,\n",
    "#                                  )\n",
    "\n",
    "# params = {\n",
    "#     \"n_estimators\": randint(2, 300), # default 100\n",
    "#     \"colsample_bytree\": uniform(0.1, 1),\n",
    "#     \"gamma\": uniform(0.1, 1),\n",
    "#     \"max_depth\": randint(2, 7), # default 3\n",
    "#     \"subsample\": uniform(0.1, 1)\n",
    "# }\n",
    "\n",
    "# xgb_model = RandomizedSearchCV(xgb_model_clf, \n",
    "#                             param_distributions=params, \n",
    "#                             random_state=42, \n",
    "#                             n_iter=200, \n",
    "#                             cv=5, \n",
    "#                             verbose=5, \n",
    "#                             n_jobs=-1, \n",
    "#                             return_train_score=True,\n",
    "#                             scoring='balanced_accuracy')\n",
    "\n",
    "# xgb_model.fit(X_train_smote, y_train_smote, sample_weight=classes_weights)\n",
    "\n",
    "# print(\"\\nBest parameter:\", xgb_model.best_params_)\n",
    "# print(\"Training set cross-validation balanced accuracy score:\", xgb_model.best_score_) \n",
    "# print(\"Test set balanced accuracy score:\", balanced_accuracy_score(y_test, xgb_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0179ed4",
   "metadata": {},
   "source": [
    "\n",
    "Best parameter: {'colsample_bytree': 0.7955160864261275, 'gamma': 0.2393314544058757, 'max_depth': 6, 'n_estimators': 144, 'subsample': 0.8555511385430487}\n",
    "Training set cross-validation balanced accuracy score: 0.88491362869749\n",
    "Test set balanced accuracy score: 0.7616455441270329"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d9fbf1",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40599fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set balanced accuracy score: 0.7743044371605187\n"
     ]
    }
   ],
   "source": [
    "xgb_final = xgb.XGBClassifier(objective=\"multi:softmax\",\n",
    "                              n_estimators= 144,\n",
    "                              max_depth= 3,\n",
    "                              gamma= 0.2393314,\n",
    "                              booster='gbtree',\n",
    "                              subsample=0.8555511385430487,\n",
    "                              colsample_bytree =0.7955160864261275,\n",
    "                                eval_metric='mlogloss',\n",
    "                                use_label_encoder=False)\n",
    "\n",
    "xgb_final.fit(X_train_smote, y_train_smote, sample_weight=classes_weights)\n",
    "\n",
    "print(\"Test set balanced accuracy score:\", balanced_accuracy_score(y_test, xgb_final.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce79a22b",
   "metadata": {},
   "source": [
    "##### Accuracy per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42e85a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 2 Accuracy:  0.951\n",
      "class 1 Accuracy:  0.493\n",
      "class 0 Accuracy:  0.879\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_final.predict(X_test)\n",
    "\n",
    "for y_i in np.unique(y_test)[::-1]:    \n",
    "    # Find the indices of y_i in the true labels\n",
    "    indices_i = np.where(y_test == y_i)\n",
    "    \n",
    "    # Computes the accuracy\n",
    "    print('class', y_i, 'Accuracy: ', str(round(np.sum(y_test[indices_i] == y_pred[indices_i])/ len(np.where(y_test==y_i)[0]), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b6fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053178a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a1e2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bbfab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e4988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23a83318",
   "metadata": {},
   "source": [
    "# Normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d8b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.rvs(0, .1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 0\n",
    "scale = 1\n",
    "plt.figure()\n",
    "plt.hist(norm.rvs(loc, scale, 1000000), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d55aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(uniform.rvs(0, 0.5, 100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c7bb4d",
   "metadata": {},
   "source": [
    "# Uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6885bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(uniform.rvs(1, 20, 100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ffb346",
   "metadata": {},
   "source": [
    "# Log uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fd1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(loguniform.rvs(0.1, 10, size=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70614520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

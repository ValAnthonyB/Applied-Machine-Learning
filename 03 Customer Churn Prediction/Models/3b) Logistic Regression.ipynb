{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96dbc127",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cb55a2",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7646ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 2739, 1: 2739})\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv('C:/Users/vabalagon/Desktop/Machine Learning Projects/Applied-Machine-Learning-Projects/Customer Churn Prediction/data/processed.csv')\n",
    "\n",
    "# Get the features and target variable from the dataframe\n",
    "X = df.drop(['state', 'area_code', 'churn'], axis=1).to_numpy()\n",
    "y = df['churn'].to_numpy()\n",
    "\n",
    "# Split into training and testing parts\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.copy(), y, \n",
    "                                                    test_size = 0.25, \n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y) #, stratify=y_smote\n",
    "# Apply SMOTE oversampling technique to the training set\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(y_train_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3566c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1711c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "989adcde",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a05ea788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2afba0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(classifier, X_test, y_test):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    for y_i in np.unique(y_test)[::-1]:\n",
    "        print()\n",
    "\n",
    "        # Find the indices of y_i in the true labels\n",
    "        indices_i = np.where(y_test == y_i)\n",
    "\n",
    "        # Computes the accuracy\n",
    "        print('class', y_i, 'Accuracy: ', str(round(np.sum(y_test[indices_i] == y_pred[indices_i])/ len(np.where(y_test==y_i)[0]), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2882e086",
   "metadata": {},
   "source": [
    "### Plain logistic regression model with L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3083905d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "[CV 1/5] END .......C=1e-05;, score=(train=0.584, test=0.644) total time=   0.0s\n",
      "[CV 2/5] END .......C=1e-05;, score=(train=0.590, test=0.629) total time=   0.0s\n",
      "[CV 3/5] END .......C=1e-05;, score=(train=0.595, test=0.614) total time=   0.0s\n",
      "[CV 4/5] END .......C=1e-05;, score=(train=0.609, test=0.559) total time=   0.0s\n",
      "[CV 5/5] END .......C=1e-05;, score=(train=0.616, test=0.550) total time=   0.0s\n",
      "[CV 1/5] END ......C=0.0001;, score=(train=0.606, test=0.667) total time=   0.0s\n",
      "[CV 2/5] END ......C=0.0001;, score=(train=0.618, test=0.625) total time=   0.0s\n",
      "[CV 3/5] END ......C=0.0001;, score=(train=0.607, test=0.639) total time=   0.0s\n",
      "[CV 4/5] END ......C=0.0001;, score=(train=0.627, test=0.563) total time=   0.0s\n",
      "[CV 5/5] END ......C=0.0001;, score=(train=0.622, test=0.563) total time=   0.1s\n",
      "[CV 1/5] END .......C=0.001;, score=(train=0.703, test=0.769) total time=   0.1s\n",
      "[CV 2/5] END .......C=0.001;, score=(train=0.710, test=0.690) total time=   0.1s\n",
      "[CV 3/5] END .......C=0.001;, score=(train=0.701, test=0.733) total time=   0.2s\n",
      "[CV 4/5] END .......C=0.001;, score=(train=0.714, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END .......C=0.001;, score=(train=0.712, test=0.660) total time=   0.1s\n",
      "[CV 1/5] END ........C=0.01;, score=(train=0.753, test=0.796) total time=   0.5s\n",
      "[CV 2/5] END ........C=0.01;, score=(train=0.768, test=0.738) total time=   0.2s\n",
      "[CV 3/5] END ........C=0.01;, score=(train=0.761, test=0.800) total time=   0.2s\n",
      "[CV 4/5] END ........C=0.01;, score=(train=0.777, test=0.743) total time=   0.4s\n",
      "[CV 5/5] END ........C=0.01;, score=(train=0.770, test=0.720) total time=   0.4s\n",
      "[CV 1/5] END .........C=0.1;, score=(train=0.770, test=0.809) total time=   0.3s\n",
      "[CV 2/5] END .........C=0.1;, score=(train=0.777, test=0.769) total time=   0.5s\n",
      "[CV 3/5] END .........C=0.1;, score=(train=0.779, test=0.793) total time=   0.4s\n",
      "[CV 4/5] END .........C=0.1;, score=(train=0.789, test=0.747) total time=   0.5s\n",
      "[CV 5/5] END .........C=0.1;, score=(train=0.787, test=0.760) total time=   0.8s\n",
      "[CV 1/5] END .........C=1.0;, score=(train=0.771, test=0.818) total time=   0.7s\n",
      "[CV 2/5] END .........C=1.0;, score=(train=0.780, test=0.772) total time=   0.4s\n",
      "[CV 3/5] END .........C=1.0;, score=(train=0.782, test=0.790) total time=   0.4s\n",
      "[CV 4/5] END .........C=1.0;, score=(train=0.794, test=0.751) total time=   0.6s\n",
      "[CV 5/5] END .........C=1.0;, score=(train=0.790, test=0.785) total time=   0.6s\n",
      "[CV 1/5] END ........C=10.0;, score=(train=0.776, test=0.817) total time=   0.6s\n",
      "[CV 2/5] END ........C=10.0;, score=(train=0.780, test=0.760) total time=   0.2s\n",
      "[CV 3/5] END ........C=10.0;, score=(train=0.786, test=0.784) total time=   0.3s\n",
      "[CV 4/5] END ........C=10.0;, score=(train=0.795, test=0.750) total time=   0.3s\n",
      "[CV 5/5] END ........C=10.0;, score=(train=0.790, test=0.784) total time=   0.7s\n",
      "[CV 1/5] END .......C=100.0;, score=(train=0.771, test=0.810) total time=   0.1s\n",
      "[CV 2/5] END .......C=100.0;, score=(train=0.779, test=0.760) total time=   0.2s\n",
      "[CV 3/5] END .......C=100.0;, score=(train=0.783, test=0.791) total time=   0.4s\n",
      "[CV 4/5] END .......C=100.0;, score=(train=0.794, test=0.751) total time=   0.3s\n",
      "[CV 5/5] END .......C=100.0;, score=(train=0.789, test=0.784) total time=   0.6s\n",
      "[CV 1/5] END ......C=1000.0;, score=(train=0.776, test=0.817) total time=   0.6s\n",
      "[CV 2/5] END ......C=1000.0;, score=(train=0.783, test=0.759) total time=   0.2s\n",
      "[CV 3/5] END ......C=1000.0;, score=(train=0.782, test=0.791) total time=   0.4s\n",
      "[CV 4/5] END ......C=1000.0;, score=(train=0.795, test=0.751) total time=   0.4s\n",
      "[CV 5/5] END ......C=1000.0;, score=(train=0.790, test=0.784) total time=   0.4s\n",
      "[CV 1/5] END .....C=10000.0;, score=(train=0.776, test=0.818) total time=   0.5s\n",
      "[CV 2/5] END .....C=10000.0;, score=(train=0.781, test=0.760) total time=   0.2s\n",
      "[CV 3/5] END .....C=10000.0;, score=(train=0.783, test=0.791) total time=   0.5s\n",
      "[CV 4/5] END .....C=10000.0;, score=(train=0.795, test=0.750) total time=   0.4s\n",
      "[CV 5/5] END .....C=10000.0;, score=(train=0.790, test=0.784) total time=   0.4s\n",
      "[CV 1/5] END ....C=100000.0;, score=(train=0.776, test=0.817) total time=   0.3s\n",
      "[CV 2/5] END ....C=100000.0;, score=(train=0.781, test=0.760) total time=   0.2s\n",
      "[CV 3/5] END ....C=100000.0;, score=(train=0.787, test=0.786) total time=   0.1s\n",
      "[CV 4/5] END ....C=100000.0;, score=(train=0.795, test=0.750) total time=   0.3s\n",
      "[CV 5/5] END ....C=100000.0;, score=(train=0.791, test=0.781) total time=   0.4s\n",
      "\n",
      "Best parameter: {'C': 1.0}\n",
      "Training set cross-validation balanced accuracy score: 0.7833051409486791\n",
      "Test set balanced accuracy score: 0.7545418035779481\n"
     ]
    }
   ],
   "source": [
    "logreg_plain_clf_l2 = LogisticRegression(penalty=\"l2\", \n",
    "                                      max_iter=5000, \n",
    "                                      class_weight='balanced')\n",
    "\n",
    "\n",
    "# The task is to find the best regularization parameter. Note that C is the inverse of the regularization parameter. \n",
    "# The smaller C is, the stronger the regularization effect\n",
    "C_range = np.logspace(-5, 5, 11)  # np.abs(np.random.normal(8.5, 3, 10)) \n",
    "param_grid = dict(C=C_range) \n",
    "\n",
    "\n",
    "# Grid search step\n",
    "logreg_plain_l2 = GridSearchCV(logreg_plain_clf_l2, param_grid, cv=5, \n",
    "                               scoring='balanced_accuracy', error_score=\"raise\", \n",
    "                               return_train_score=True, verbose=5)\n",
    "\n",
    "logreg_plain_l2.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameter and the best score\n",
    "print(\"\\nBest parameter:\", logreg_plain_l2.best_params_)\n",
    "print(\"Training set cross-validation balanced accuracy score:\", logreg_plain_l2.best_score_) \n",
    "print(\"Test set balanced accuracy score:\", balanced_accuracy_score(y_test, logreg_plain_l2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6578a6",
   "metadata": {},
   "source": [
    "##### Accuracy per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e53aca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "class 1 Accuracy:  0.753\n",
      "\n",
      "class 0 Accuracy:  0.756\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_class(logreg_plain_l2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d1c907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd1dc90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a0b356e",
   "metadata": {},
   "source": [
    "### Plain LogReg with SMOTE oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47129438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "[CV 1/5] END .......C=1e-05;, score=(train=0.594, test=0.611) total time=   0.0s\n",
      "[CV 2/5] END .......C=1e-05;, score=(train=0.593, test=0.606) total time=   0.0s\n",
      "[CV 3/5] END .......C=1e-05;, score=(train=0.597, test=0.585) total time=   0.0s\n",
      "[CV 4/5] END .......C=1e-05;, score=(train=0.599, test=0.589) total time=   0.0s\n",
      "[CV 5/5] END .......C=1e-05;, score=(train=0.601, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END ......C=0.0001;, score=(train=0.636, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END ......C=0.0001;, score=(train=0.634, test=0.653) total time=   0.1s\n",
      "[CV 3/5] END ......C=0.0001;, score=(train=0.643, test=0.617) total time=   0.0s\n",
      "[CV 4/5] END ......C=0.0001;, score=(train=0.645, test=0.611) total time=   0.1s\n",
      "[CV 5/5] END ......C=0.0001;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 1/5] END .......C=0.001;, score=(train=0.731, test=0.737) total time=   0.4s\n",
      "[CV 2/5] END .......C=0.001;, score=(train=0.729, test=0.758) total time=   0.3s\n",
      "[CV 3/5] END .......C=0.001;, score=(train=0.729, test=0.718) total time=   0.3s\n",
      "[CV 4/5] END .......C=0.001;, score=(train=0.736, test=0.712) total time=   0.3s\n",
      "[CV 5/5] END .......C=0.001;, score=(train=0.730, test=0.730) total time=   0.2s\n",
      "[CV 1/5] END ........C=0.01;, score=(train=0.780, test=0.775) total time=   0.5s\n",
      "[CV 2/5] END ........C=0.01;, score=(train=0.775, test=0.796) total time=   0.3s\n",
      "[CV 3/5] END ........C=0.01;, score=(train=0.777, test=0.782) total time=   0.8s\n",
      "[CV 4/5] END ........C=0.01;, score=(train=0.783, test=0.759) total time=   0.7s\n",
      "[CV 5/5] END ........C=0.01;, score=(train=0.779, test=0.779) total time=   0.6s\n",
      "[CV 1/5] END .........C=0.1;, score=(train=0.800, test=0.772) total time=   0.5s\n",
      "[CV 2/5] END .........C=0.1;, score=(train=0.788, test=0.815) total time=   0.7s\n",
      "[CV 3/5] END .........C=0.1;, score=(train=0.791, test=0.801) total time=   0.9s\n",
      "[CV 4/5] END .........C=0.1;, score=(train=0.800, test=0.777) total time=   0.6s\n",
      "[CV 5/5] END .........C=0.1;, score=(train=0.793, test=0.805) total time=   0.6s\n",
      "[CV 1/5] END .........C=1.0;, score=(train=0.802, test=0.776) total time=   0.3s\n",
      "[CV 2/5] END .........C=1.0;, score=(train=0.793, test=0.818) total time=   0.6s\n",
      "[CV 3/5] END .........C=1.0;, score=(train=0.795, test=0.806) total time=   0.6s\n",
      "[CV 4/5] END .........C=1.0;, score=(train=0.803, test=0.777) total time=   0.3s\n",
      "[CV 5/5] END .........C=1.0;, score=(train=0.795, test=0.809) total time=   0.1s\n",
      "[CV 1/5] END ........C=10.0;, score=(train=0.803, test=0.778) total time=   0.4s\n",
      "[CV 2/5] END ........C=10.0;, score=(train=0.793, test=0.807) total time=   0.3s\n",
      "[CV 3/5] END ........C=10.0;, score=(train=0.792, test=0.808) total time=   0.4s\n",
      "[CV 4/5] END ........C=10.0;, score=(train=0.804, test=0.778) total time=   0.3s\n",
      "[CV 5/5] END ........C=10.0;, score=(train=0.799, test=0.807) total time=   0.5s\n",
      "[CV 1/5] END .......C=100.0;, score=(train=0.803, test=0.778) total time=   0.4s\n",
      "[CV 2/5] END .......C=100.0;, score=(train=0.794, test=0.807) total time=   0.2s\n",
      "[CV 3/5] END .......C=100.0;, score=(train=0.793, test=0.809) total time=   0.3s\n",
      "[CV 4/5] END .......C=100.0;, score=(train=0.804, test=0.779) total time=   0.3s\n",
      "[CV 5/5] END .......C=100.0;, score=(train=0.796, test=0.807) total time=   0.5s\n",
      "[CV 1/5] END ......C=1000.0;, score=(train=0.803, test=0.777) total time=   0.6s\n",
      "[CV 2/5] END ......C=1000.0;, score=(train=0.794, test=0.807) total time=   0.3s\n",
      "[CV 3/5] END ......C=1000.0;, score=(train=0.795, test=0.810) total time=   0.6s\n",
      "[CV 4/5] END ......C=1000.0;, score=(train=0.803, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ......C=1000.0;, score=(train=0.797, test=0.807) total time=   0.4s\n",
      "[CV 1/5] END .....C=10000.0;, score=(train=0.801, test=0.777) total time=   0.2s\n",
      "[CV 2/5] END .....C=10000.0;, score=(train=0.793, test=0.818) total time=   0.4s\n",
      "[CV 3/5] END .....C=10000.0;, score=(train=0.793, test=0.808) total time=   0.4s\n",
      "[CV 4/5] END .....C=10000.0;, score=(train=0.805, test=0.779) total time=   0.4s\n",
      "[CV 5/5] END .....C=10000.0;, score=(train=0.798, test=0.807) total time=   0.6s\n",
      "[CV 1/5] END ....C=100000.0;, score=(train=0.801, test=0.778) total time=   0.3s\n",
      "[CV 2/5] END ....C=100000.0;, score=(train=0.794, test=0.808) total time=   0.4s\n",
      "[CV 3/5] END ....C=100000.0;, score=(train=0.793, test=0.807) total time=   0.3s\n",
      "[CV 4/5] END ....C=100000.0;, score=(train=0.805, test=0.778) total time=   0.9s\n",
      "[CV 5/5] END ....C=100000.0;, score=(train=0.796, test=0.807) total time=   0.2s\n",
      "\n",
      "Best parameter: {'C': 1.0}\n",
      "Training set cross-validation balanced accuracy score: 0.7981027902694191\n",
      "Test set balanced accuracy score: 0.7461847389558233\n"
     ]
    }
   ],
   "source": [
    "logreg_plain_clf_l2 = LogisticRegression(penalty=\"l2\", \n",
    "                                      max_iter=5000, \n",
    "                                      class_weight='balanced')\n",
    "\n",
    "\n",
    "# The task is to find the best regularization parameter. Note that C is the inverse of the regularization parameter. \n",
    "# The smaller C is, the stronger the regularization effect\n",
    "C_range = np.logspace(-5, 5, 11)  # np.abs(np.random.normal(8.5, 3, 10)) \n",
    "param_grid = dict(C=C_range) \n",
    "\n",
    "\n",
    "# Grid search step\n",
    "logreg_plain_l2_smote = GridSearchCV(logreg_plain_clf_l2, param_grid, cv=5, \n",
    "                               scoring='balanced_accuracy', error_score=\"raise\", \n",
    "                               return_train_score=True, verbose=5)\n",
    "\n",
    "logreg_plain_l2_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Print the best parameter and the best score\n",
    "print(\"\\nBest parameter:\", logreg_plain_l2.best_params_)\n",
    "print(\"Training set cross-validation balanced accuracy score:\", logreg_plain_l2_smote.best_score_) \n",
    "print(\"Test set balanced accuracy score:\", balanced_accuracy_score(y_test, logreg_plain_l2_smote.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f766732d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "class 1 Accuracy:  0.733\n",
      "\n",
      "class 0 Accuracy:  0.759\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_class(logreg_plain_l2_smote, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b92bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba866d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07a8aaba",
   "metadata": {},
   "source": [
    "### Logistic Regression with Polynomial features and L2 regularization (no SMOTE)\n",
    "\n",
    "Steps:\n",
    "1. Fit the data X to Polynomial Features\n",
    "2. Split training and testing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59c1fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bde77f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 2739, 1: 2739})\n"
     ]
    }
   ],
   "source": [
    "# Transform the add polynomial features to the original dataset\n",
    "poly_log_reg = PolynomialFeatures(2)\n",
    "X_poly_logreg = poly_log_reg.fit_transform(X.copy())\n",
    "\n",
    "# Apply standard scaling on the dataset\n",
    "X_poly_logreg = StandardScaler().fit_transform(X_poly_logreg)\n",
    "\n",
    "# Test-train split\n",
    "X_train_poly_logreg, X_test_poly_logreg, y_train_poly_logreg, y_test_poly_logreg = train_test_split(X_poly_logreg, \n",
    "                                                                                                    y, \n",
    "                                                                                                    test_size = 0.25,\n",
    "                                                                                                    stratify=y)\n",
    "\n",
    "# Apply SMOTE oversampling algorithm to the training set\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_smote_poly, y_train_smote_poly = sm.fit_resample(X_train_poly_logreg, y_train_poly_logreg)\n",
    "print('Resampled dataset shape %s' % Counter(y_train_smote_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe68bb",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d2d8bae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END ......C=0.0001;, score=(train=0.771, test=0.781) total time=   0.0s\n",
      "[CV 2/5] END ......C=0.0001;, score=(train=0.771, test=0.800) total time=   0.0s\n",
      "[CV 3/5] END ......C=0.0001;, score=(train=0.766, test=0.751) total time=   0.0s\n",
      "[CV 4/5] END ......C=0.0001;, score=(train=0.780, test=0.751) total time=   0.0s\n",
      "[CV 5/5] END ......C=0.0001;, score=(train=0.771, test=0.769) total time=   0.0s\n",
      "[CV 1/5] END .......C=0.001;, score=(train=0.791, test=0.799) total time=   0.0s\n",
      "[CV 2/5] END .......C=0.001;, score=(train=0.786, test=0.800) total time=   0.0s\n",
      "[CV 3/5] END .......C=0.001;, score=(train=0.792, test=0.767) total time=   0.0s\n",
      "[CV 4/5] END .......C=0.001;, score=(train=0.790, test=0.770) total time=   0.0s\n",
      "[CV 5/5] END .......C=0.001;, score=(train=0.790, test=0.793) total time=   0.0s\n",
      "[CV 1/5] END ........C=0.01;, score=(train=0.816, test=0.818) total time=   0.0s\n",
      "[CV 2/5] END ........C=0.01;, score=(train=0.809, test=0.825) total time=   0.0s\n",
      "[CV 3/5] END ........C=0.01;, score=(train=0.829, test=0.792) total time=   0.0s\n",
      "[CV 4/5] END ........C=0.01;, score=(train=0.818, test=0.818) total time=   0.0s\n",
      "[CV 5/5] END ........C=0.01;, score=(train=0.819, test=0.827) total time=   0.0s\n",
      "[CV 1/5] END .........C=0.1;, score=(train=0.846, test=0.857) total time=   0.0s\n",
      "[CV 2/5] END .........C=0.1;, score=(train=0.852, test=0.828) total time=   0.0s\n",
      "[CV 3/5] END .........C=0.1;, score=(train=0.856, test=0.824) total time=   0.0s\n",
      "[CV 4/5] END .........C=0.1;, score=(train=0.852, test=0.836) total time=   0.0s\n",
      "[CV 5/5] END .........C=0.1;, score=(train=0.841, test=0.859) total time=   0.0s\n",
      "[CV 1/5] END .........C=1.0;, score=(train=0.850, test=0.867) total time=   0.0s\n",
      "[CV 2/5] END .........C=1.0;, score=(train=0.858, test=0.820) total time=   0.0s\n",
      "[CV 3/5] END .........C=1.0;, score=(train=0.862, test=0.825) total time=   0.0s\n",
      "[CV 4/5] END .........C=1.0;, score=(train=0.863, test=0.842) total time=   0.0s\n",
      "[CV 5/5] END .........C=1.0;, score=(train=0.854, test=0.846) total time=   0.0s\n",
      "[CV 1/5] END ........C=10.0;, score=(train=0.850, test=0.864) total time=   0.2s\n",
      "[CV 2/5] END ........C=10.0;, score=(train=0.862, test=0.822) total time=   0.2s\n",
      "[CV 3/5] END ........C=10.0;, score=(train=0.866, test=0.811) total time=   0.2s\n",
      "[CV 4/5] END ........C=10.0;, score=(train=0.858, test=0.853) total time=   0.2s\n",
      "[CV 5/5] END ........C=10.0;, score=(train=0.856, test=0.840) total time=   0.2s\n",
      "[CV 1/5] END .......C=100.0;, score=(train=0.849, test=0.864) total time=   0.7s\n",
      "[CV 2/5] END .......C=100.0;, score=(train=0.866, test=0.813) total time=   0.8s\n",
      "[CV 3/5] END .......C=100.0;, score=(train=0.867, test=0.803) total time=   0.6s\n",
      "[CV 4/5] END .......C=100.0;, score=(train=0.859, test=0.852) total time=   0.7s\n",
      "[CV 5/5] END .......C=100.0;, score=(train=0.857, test=0.836) total time=   0.5s\n",
      "[CV 1/5] END ......C=1000.0;, score=(train=0.852, test=0.861) total time=   2.1s\n",
      "[CV 2/5] END ......C=1000.0;, score=(train=0.872, test=0.814) total time=   1.2s\n",
      "[CV 3/5] END ......C=1000.0;, score=(train=0.868, test=0.804) total time=   1.5s\n",
      "[CV 4/5] END ......C=1000.0;, score=(train=0.860, test=0.850) total time=   1.4s\n",
      "[CV 5/5] END ......C=1000.0;, score=(train=0.857, test=0.837) total time=   1.5s\n",
      "[CV 1/5] END .....C=10000.0;, score=(train=0.857, test=0.867) total time=   2.2s\n",
      "[CV 2/5] END .....C=10000.0;, score=(train=0.870, test=0.812) total time=   4.3s\n",
      "[CV 3/5] END .....C=10000.0;, score=(train=0.869, test=0.802) total time=   2.9s\n",
      "[CV 4/5] END .....C=10000.0;, score=(train=0.863, test=0.846) total time=   4.0s\n",
      "[CV 5/5] END .....C=10000.0;, score=(train=0.857, test=0.837) total time=   1.7s\n",
      "\n",
      "Best parameter: {'C': 0.1}\n",
      "Training set cross-validation balanced accuracy score: 0.8406651277371013\n",
      "Test set balanced accuracy score: 0.8489010587805769\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "logreg_poly_clf = LogisticRegression(penalty=\"l2\", \n",
    "                                     max_iter=10000, \n",
    "                                     class_weight='balanced') #\n",
    "\n",
    "# Dictionary of possible parameter values per parameter\n",
    "C_range = np.logspace(-4, 4, 9) #np.abs(np.random.normal(0.1, .01, 20))\n",
    "param_grid = dict(C=C_range) # Note that C is the inverse of the regularization parameter\n",
    "\n",
    "# Grid search step\n",
    "logreg_poly = GridSearchCV(logreg_poly_clf, param_grid, cv=5, \n",
    "                           scoring='balanced_accuracy', \n",
    "                           return_train_score=True, \n",
    "                           verbose=5)\n",
    "logreg_poly.fit(X_train_poly_logreg, y_train_poly_logreg)\n",
    "\n",
    "# Print the best parameter and the best score\n",
    "print(\"\\nBest parameter:\", logreg_poly.best_params_)\n",
    "print(\"Training set cross-validation balanced accuracy score:\", logreg_poly.best_score_) \n",
    "print(\"Test set balanced accuracy score:\", balanced_accuracy_score(y_test_poly_logreg, logreg_poly.predict(X_test_poly_logreg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b78d58ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "class 1 Accuracy:  0.853\n",
      "\n",
      "class 0 Accuracy:  0.844\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_class(logreg_poly, X_test_poly_logreg, y_test_poly_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0d5959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bfa98a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f674786b",
   "metadata": {},
   "source": [
    "### LogReg with Polynomial Features with l2 regularization and SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f56e67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[CV 1/5] END .......C=0.001;, score=(train=0.805, test=0.814) total time=   0.0s\n",
      "[CV 2/5] END .......C=0.001;, score=(train=0.805, test=0.820) total time=   0.0s\n",
      "[CV 3/5] END .......C=0.001;, score=(train=0.807, test=0.807) total time=   0.0s\n",
      "[CV 4/5] END .......C=0.001;, score=(train=0.807, test=0.798) total time=   0.0s\n",
      "[CV 5/5] END .......C=0.001;, score=(train=0.810, test=0.795) total time=   0.0s\n",
      "[CV 1/5] END ........C=0.01;, score=(train=0.834, test=0.840) total time=   0.0s\n",
      "[CV 2/5] END ........C=0.01;, score=(train=0.835, test=0.842) total time=   0.0s\n",
      "[CV 3/5] END ........C=0.01;, score=(train=0.835, test=0.840) total time=   0.0s\n",
      "[CV 4/5] END ........C=0.01;, score=(train=0.837, test=0.826) total time=   0.0s\n",
      "[CV 5/5] END ........C=0.01;, score=(train=0.839, test=0.824) total time=   0.0s\n",
      "[CV 1/5] END .........C=0.1;, score=(train=0.863, test=0.869) total time=   0.0s\n",
      "[CV 2/5] END .........C=0.1;, score=(train=0.862, test=0.866) total time=   0.0s\n",
      "[CV 3/5] END .........C=0.1;, score=(train=0.863, test=0.867) total time=   0.0s\n",
      "[CV 4/5] END .........C=0.1;, score=(train=0.863, test=0.843) total time=   0.0s\n",
      "[CV 5/5] END .........C=0.1;, score=(train=0.868, test=0.851) total time=   0.0s\n",
      "[CV 1/5] END .........C=1.0;, score=(train=0.873, test=0.867) total time=   0.1s\n",
      "[CV 2/5] END .........C=1.0;, score=(train=0.873, test=0.876) total time=   0.1s\n",
      "[CV 3/5] END .........C=1.0;, score=(train=0.869, test=0.880) total time=   0.1s\n",
      "[CV 4/5] END .........C=1.0;, score=(train=0.873, test=0.861) total time=   0.1s\n",
      "[CV 5/5] END .........C=1.0;, score=(train=0.875, test=0.857) total time=   0.1s\n",
      "[CV 1/5] END ........C=10.0;, score=(train=0.876, test=0.867) total time=   0.4s\n",
      "[CV 2/5] END ........C=10.0;, score=(train=0.872, test=0.882) total time=   0.4s\n",
      "[CV 3/5] END ........C=10.0;, score=(train=0.874, test=0.880) total time=   0.3s\n",
      "[CV 4/5] END ........C=10.0;, score=(train=0.877, test=0.860) total time=   0.4s\n",
      "[CV 5/5] END ........C=10.0;, score=(train=0.875, test=0.862) total time=   0.4s\n",
      "[CV 1/5] END .......C=100.0;, score=(train=0.876, test=0.867) total time=   1.0s\n",
      "[CV 2/5] END .......C=100.0;, score=(train=0.873, test=0.881) total time=   1.0s\n",
      "[CV 3/5] END .......C=100.0;, score=(train=0.874, test=0.879) total time=   1.0s\n",
      "[CV 4/5] END .......C=100.0;, score=(train=0.877, test=0.860) total time=   1.0s\n",
      "[CV 5/5] END .......C=100.0;, score=(train=0.876, test=0.858) total time=   1.0s\n",
      "[CV 1/5] END ......C=1000.0;, score=(train=0.879, test=0.868) total time=   2.6s\n",
      "[CV 2/5] END ......C=1000.0;, score=(train=0.873, test=0.883) total time=   2.5s\n",
      "[CV 3/5] END ......C=1000.0;, score=(train=0.873, test=0.879) total time=   2.8s\n",
      "[CV 4/5] END ......C=1000.0;, score=(train=0.877, test=0.863) total time=   2.3s\n",
      "[CV 5/5] END ......C=1000.0;, score=(train=0.877, test=0.860) total time=   2.3s\n",
      "\n",
      "Best parameter: {'C': 1000.0}\n",
      "Training set cross-validation balanced accuracy score: 0.8705653931864583\n",
      "Test set balanced accuracy score: 0.8481161007667031\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "logreg_poly_clf = LogisticRegression(penalty=\"l2\", \n",
    "                                     max_iter=10000, \n",
    "                                     class_weight='balanced') #\n",
    "\n",
    "# Dictionary of possible parameter values per parameter\n",
    "C_range = np.logspace(-3, 3, 7) #np.abs(np.random.normal(0.1, .01, 20))\n",
    "param_grid = dict(C=C_range) # Note that C is the inverse of the regularization parameter\n",
    "\n",
    "# Grid search step\n",
    "logreg_poly = GridSearchCV(logreg_poly_clf, param_grid, cv=5, \n",
    "                           scoring='balanced_accuracy', \n",
    "                           return_train_score=True, \n",
    "                           verbose=5)\n",
    "logreg_poly.fit(X_train_smote_poly, y_train_smote_poly)\n",
    "\n",
    "# Print the best parameter and the best score\n",
    "print(\"\\nBest parameter:\", logreg_poly.best_params_)\n",
    "print(\"Training set cross-validation balanced accuracy score:\", logreg_poly.best_score_) \n",
    "print(\"Test set balanced accuracy score:\", balanced_accuracy_score(y_test_poly_logreg, logreg_poly.predict(X_test_poly_logreg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "322a33b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "class 1 Accuracy:  0.82\n",
      "\n",
      "class 0 Accuracy:  0.876\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_class(logreg_poly, X_test_poly_logreg, y_test_poly_logreg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
